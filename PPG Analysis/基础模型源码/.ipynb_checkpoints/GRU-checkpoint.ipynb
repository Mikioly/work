{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ba2b500-62f8-4395-aa94-6db1781468ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "718fc0b2-7750-4474-8bef-03bc91eed991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2419,  0.4648, -0.4883, -1.1455,  0.2463],\n",
      "         [-0.5579,  0.3708, -0.4725, -1.0375,  0.3324],\n",
      "         [-0.8012,  0.4762, -0.4361, -0.8410,  0.4185]],\n",
      "\n",
      "        [[ 0.9285, -0.2837, -0.0574,  0.5011, -0.5571],\n",
      "         [ 0.3154, -0.0776,  0.1312,  0.1449, -0.3146],\n",
      "         [-0.2662,  0.1968,  0.0817,  0.0113, -0.1194]]],\n",
      "       grad_fn=<TransposeBackward1>)\n",
      "weight_ih_l0 torch.Size([15, 4])\n",
      "weight_hh_l0 torch.Size([15, 5])\n",
      "bias_ih_l0 torch.Size([15])\n",
      "bias_hh_l0 torch.Size([15])\n",
      "tensor([[[-0.2419,  0.4648, -0.4883, -1.1455,  0.2463],\n",
      "         [-0.5579,  0.3708, -0.4725, -1.0375,  0.3324],\n",
      "         [-0.8012,  0.4762, -0.4361, -0.8410,  0.4185]],\n",
      "\n",
      "        [[ 0.9285, -0.2837, -0.0574,  0.5011, -0.5571],\n",
      "         [ 0.3154, -0.0776,  0.1312,  0.1449, -0.3146],\n",
      "         [-0.2662,  0.1968,  0.0817,  0.0113, -0.1194]]], grad_fn=<CopySlices>)\n",
      "tensor([[-0.8012,  0.4762, -0.4361, -0.8410,  0.4185],\n",
      "        [-0.2662,  0.1968,  0.0817,  0.0113, -0.1194]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def gru_forward(input,initial_states,w_ih,w_hh,b_ih,b_hh):\n",
    "    prev_h = initial_states\n",
    "    bs,T,i_size = input.shape\n",
    "    h_size = w_ih.shape[0]//3\n",
    "    #对权重扩维，复制为batch_size倍\n",
    "    batch_w_ih = w_ih.unsqueeze(0).tile(bs,1,1)\n",
    "    batch_w_hh = w_hh.unsqueeze(0).tile(bs,1,1)\n",
    "\n",
    "    output = torch.zeros(bs,T,h_size) #GRU网络的输出状态序列\n",
    "    for t in range(T):\n",
    "        x = input[: , t, :] #t时刻gru cell 输入特征向量 bs,i_size\n",
    "        w_times_x = torch.bmm(batch_w_ih,x.unsqueeze(-1))\n",
    "        w_times_x = w_times_x.squeeze(-1)\n",
    "        w_times_h_prev = torch.bmm(batch_w_hh,prev_h.unsqueeze(-1))\n",
    "        w_times_h_prev = w_times_h_prev.squeeze(-1)\n",
    "\n",
    "        r_t = torch.sigmoid(w_times_x[:,:h_size]+w_times_h_prev[:,:h_size]+b_ih[:h_size]+b_hh[:h_size])  #重置门\n",
    "        z_t = torch.sigmoid(w_times_x[:,h_size:2*h_size]+w_times_h_prev[:,h_size:2*h_size]+b_ih[h_size:2*h_size]+b_hh[h_size:2*h_size]) #更新门\n",
    "        n_t = torch.tanh(w_times_x[:,2*h_size:3*h_size]+b_ih[2*h_size:3*h_size]+r_t*(w_times_h_prev[:,2*h_size:3*h_size]+b_hh[2*h_size:3*h_size]))#候选状态\n",
    "\n",
    "        prev_h = (1-z_t)*n_t + z_t*prev_h\n",
    "        output[: ,t,:] = prev_h\n",
    "    return output,prev_h \n",
    "\n",
    "#测试\n",
    "bs, T,i_size,h_size = 2,3,4,5\n",
    "input = torch.randn(bs,T,i_size)\n",
    "h0 = torch.randn(bs,h_size)\n",
    "\n",
    "gru_layer = nn.GRU(i_size,h_size,batch_first = True)\n",
    "output,h_final = gru_layer(input,h0.unsqueeze(0))\n",
    "print(output)\n",
    "\n",
    "for k,v in gru_layer.named_parameters():\n",
    "    print(k,v.shape)\n",
    "\n",
    "output_custom, h_final_custom = gru_forward(input,h0,gru_layer.weight_ih_l0,gru_layer.weight_hh_l0,gru_layer.bias_ih_l0,gru_layer.bias_hh_l0)\n",
    "print(output_custom)\n",
    "print(h_final_custom)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
